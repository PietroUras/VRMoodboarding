# VRMoodboarding

This repository will soon contain the codebase of my master's thesis in **Cinema and Media Engineering** at **Politecnico di Torino**.

⏳ **Note:** The code is not yet available but will be uploaded as soon as possible. Stay tuned!

---

## 🎓 Thesis Abstract

This study investigates the effectiveness of multimodal interaction techniques within a spatial computing context, applied to a moodboarding system based on AI-generated images.

Three interaction modes are tested:

- 🎛️ A traditional interface relying on virtual buttons  
- ✋ A gesture-driven configuration using hand tracking for key operations such as triggering image generation, initiating speech recognition, and navigating the UI  
- 🔁 A hybrid interface combining both modalities

In addition to evaluating task accuracy, speed, and user engagement, the study explores user behavior within the hybrid setup to identify which interaction method users prefer for each type of task. This provides insights into the most congenial input strategies in creative spatial workflows.

---

## 📄 License

This work is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License** (CC BY-NC-SA 4.0).  
This means you are free to:

- 🔄 Share and adapt the material  
- 🧪 Use it for personal, research, or educational purposes  

As long as you:

- ✍️ Give appropriate credit  
- 🚫 Do not use it for commercial purposes  
- 📎 Distribute any derivative works under the same license

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
